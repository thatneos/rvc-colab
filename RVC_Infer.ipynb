{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thatneos/rvc-colab/blob/main/RVC_Infer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Install RVC\n",
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "from ipywidgets import Button\n",
        "\n",
        "start_total_t = time.time()\n",
        "\n",
        "if os.environ[\"COLAB_GPU\"]:\n",
        "  print(\"a GPU is connected. Things should be working normally.\\nIf there are any errors dm @eempostor on discord. Enjoy!\")\n",
        "else:\n",
        "  print(\"GPU isn't connected. Inference would take a long time and might crash.\\nI recommend connecting to a GPU. You have been warned.\")\n",
        "\n",
        "main_dir = \"/content/rvc\"\n",
        "#@markdown (OPTIONAL) Mount your google drive to the runtime.\n",
        "mount_drive = False #@param {type:\"boolean\"}\n",
        "\n",
        "if mount_drive and not os.path.exists(\"/content/drive\"):\n",
        "  start_mount_t = time.time()\n",
        "  print(\"- Mounting drive.\")\n",
        "  drive.mount(\"/content/drive\")\n",
        "  end_mount_t = time.time()\n",
        "  print(f\"- Mounting completed! ({round(end_mount_t-start_mount_t, 2)}s)\")\n",
        "if not os.path.exists(main_dir):\n",
        "  start_download_t = time.time()\n",
        "  print(\"- Downloading files for inference.\")\n",
        "  !git clone -q https://huggingface.co/Thatneos/rvc\n",
        "  os.chdir(main_dir)\n",
        "  !wget -q -O assets/fcpe/fcpe.pt https://huggingface.co/datasets/NeoPy/rvc-base/resolve/main/fcpe.pt\n",
        "  !wget -q -O assets/hubert/hubert_base.pt https://huggingface.co/NeoPy/rvc-base/resolve/main/hubert_base.pt\n",
        "  !wget -q -O assets/rmvpe/rmvpe.pt https://huggingface.co/NeoPy/rvc-base/resolve/main/rmvpe.pt\n",
        "  end_download_t = time.time()\n",
        "  print(f\"- Downloading completed! ({round(end_download_t-start_download_t, 2)}s)\")\n",
        "else:\n",
        "  print(\"- Files are already downloaded.\")\n",
        "start_install_t = time.time()\n",
        "print(\"- Installing dependencies.\")\n",
        "!pip install pip==24.0\n",
        "!pip install -q av uv\n",
        "!uv pip install -q ffmpeg-python>=0.2.0\n",
        "!uv pip install -q faiss_cpu==1.7.3\n",
        "!uv pip install -q praat-parselmouth==0.4.2\n",
        "!uv pip install -q pyworld==0.3.4\n",
        "!uv pip install -q resampy==0.4.2\n",
        "!uv pip install -q fairseq==0.12.2\n",
        "!uv pip install -q pydub==0.25.1\n",
        "!uv pip install -q einops\n",
        "!uv pip install -q local_attention\n",
        "!uv pip install -q torchcrepe==0.0.23\n",
        "!uv pip install -q torchfcpe\n",
        "!uv pip install -q audio-separator[gpu]==0.30.1\n",
        "!uv pip install -q  git+https://github.com/One-sixth/fairseq.git\n",
        "end_install_t = time.time()\n",
        "\n",
        "\n",
        "\n",
        "Button(description=\"\\u2714 Success\", button_style=\"success\")\n",
        "\n",
        "end_total_t = time.time()\n",
        "print(f\"- Installation completed! ({round(end_install_t-start_install_t, 2)}s)\\nTotal time: {round((end_total_t-start_total_t)/60, 2)} minutes\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sBTlalhJSL7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Download models using urls\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import urllib.request\n",
        "import gdown\n",
        "import subprocess\n",
        "\n",
        "main_dir = \"/content/rvc\"\n",
        "os.chdir(main_dir)\n",
        "models_dir = \"models\"\n",
        "\n",
        "def extract_zip(extraction_folder, zip_name):\n",
        "    os.makedirs(extraction_folder)\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extraction_folder)\n",
        "    os.remove(zip_name)\n",
        "\n",
        "    index_filepath, model_filepath = None, None\n",
        "    for root, dirs, files in os.walk(extraction_folder):\n",
        "        for name in files:\n",
        "            if name.endswith('.index') and os.stat(os.path.join(root, name)).st_size > 1024 * 100:\n",
        "                index_filepath = os.path.join(root, name)\n",
        "\n",
        "            if name.endswith('.pth') and os.stat(os.path.join(root, name)).st_size > 1024 * 1024 * 40:\n",
        "                model_filepath = os.path.join(root, name)\n",
        "\n",
        "    if not model_filepath:\n",
        "        raise Exception(f'No .pth model file was found in the extracted zip. Please check {extraction_folder}.')\n",
        "\n",
        "    # move model and index file to extraction folder\n",
        "    os.rename(model_filepath, os.path.join(extraction_folder, os.path.basename(model_filepath)))\n",
        "    if index_filepath:\n",
        "        os.rename(index_filepath, os.path.join(extraction_folder, os.path.basename(index_filepath)))\n",
        "\n",
        "    # remove any unnecessary nested folders\n",
        "    for filepath in os.listdir(extraction_folder):\n",
        "        if os.path.isdir(os.path.join(extraction_folder, filepath)):\n",
        "            shutil.rmtree(os.path.join(extraction_folder, filepath))\n",
        "\n",
        "def download_online_model(url, dir_name):\n",
        "    try:\n",
        "        print(f'[~] Downloading voice model with name {dir_name}...')\n",
        "        zip_name = url.split('/')[-1]\n",
        "        extraction_folder = os.path.join(models_dir, dir_name)\n",
        "        if os.path.exists(extraction_folder):\n",
        "            raise Exception(f'Voice model directory {dir_name} already exists! Choose a different name for your voice model.')\n",
        "\n",
        "        if 'pixeldrain.com' in url:\n",
        "            url = f'https://pixeldrain.com/api/file/{zip_name}'\n",
        "        if 'drive.google.com' in url:\n",
        "          zip_name = dir_name + \".zip\"\n",
        "          gdown.download(url, output=zip_name, use_cookies=True, quiet=True, fuzzy=True)\n",
        "        else:\n",
        "        \turllib.request.urlretrieve(url, zip_name)\n",
        "\n",
        "        print(f'[~] Extracting zip file...')\n",
        "        extract_zip(extraction_folder, zip_name)\n",
        "        print(f'[+] {dir_name} Model successfully downloaded!')\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(str(e))\n",
        "\n",
        "#@markdown Enter in the model download url. The url could be a Google Drive url, HuggingFace url, or Pixeldrain url.\n",
        "url = \"\" # @param {type:\"string\"}\n",
        "#@markdown Enter in your desired model name.\n",
        "dir_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "download_online_model(url, dir_name)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "i90u61j5STOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## Inference\n",
        "import os\n",
        "main_dir = \"/content/Harmonify\"\n",
        "os.chdir(main_dir)\n",
        "from lib.infer import infer_audio\n",
        "from google.colab import files\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "\n",
        "#@markdown ### | MAIN SETTINGS |\n",
        "#@markdown Enter in your model name. It will automaticly search a folder containing the pth file and index file.\n",
        "MODEL_NAME = \"\" #@param {type:\"string\"}\n",
        "#@markdown Enter in your audio path. Leave blank to upload audio from the cell.\n",
        "SOUND_PATH = \"\" #@param {type:\"string\"}\n",
        "#@markdown Change pitches in semitones.\n",
        "F0_CHANGE = 0 #@param {type:\"integer\"}\n",
        "#@markdown Select an f0 method. You can use a custom hybrid method by typing \"hybrid[method1+method2+...]\".\n",
        "F0_METHOD = \"fcpe\" #@param [\"crepe\", \"harvest\", \"mangio-crepe\", \"rmvpe\", \"rmvpe+\", \"fcpe\", \"fcpe_legacy\", \"hybrid[mangio-crepe+rmvpe]\", \"hybrid[mangio-crepe+fcpe]\", \"hybrid[rmvpe+fcpe]\", \"hybrid[mangio-crepe+rmvpe+fcpe]\"] {allow-input:true}\n",
        "#@markdown ### | OTHER SETTINGS |\n",
        "MIN_PITCH = \"50\" #@param {type:\"string\"}\n",
        "MAX_PITCH = \"1100\" #@param {type:\"string\"}\n",
        "CREPE_HOP_LENGTH = 120 #@param {type:\"integer\"}\n",
        "INDEX_RATE = 0.75 #@param {type:\"number\"}\n",
        "FILTER_RADIUS = 3 #@param {type:\"integer\"}\n",
        "RMS_MIX_RATE = 0.25 #@param {type:\"number\"}\n",
        "PROTECT = 0.33 #@param {type:\"number\"}\n",
        "#@markdown ### | ADVANCED SETTINGS |\n",
        "#@markdown Split input audio into smaller chunks by detecting silence, infering them, and then combining them with the purpose of getting cleaner results. Turning this on will longer inference time.\n",
        "SPLIT_INFER = False #@param {type:\"boolean\"}\n",
        "#@markdown [SPLIT INFER SETTINGS] The minimum length for any silence section. Measured in miliseconds.\n",
        "MIN_SILENCE = 500 #@param {type:\"number\"}\n",
        "#@markdown [SPLIT INFER SETTINGS] The upper bound for how quiet is silence in dFBS.\n",
        "SILENCE_THRESHOLD = -50 #@param {type:\"number\"}\n",
        "#@markdown [SPLIT INFER SETTINGS] Step size for interating over the audio in ms.\n",
        "SEEK_STEP = 1 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "#@markdown [SPLIT INFER SETTINGS] Leave some silence at the beginning and end of the chunks to keep the audio from sounding like it is abruptly cut off. Measured in miliseconds.\n",
        "KEEP_SILENCE = 200 #@param {type:\"number\"}\n",
        "#@markdown Turn on for a better male to female and vice versa conversion. Turning this on will **significantly** longer inference time. (VERY EXPERIMENTAL).\n",
        "FORMANT_SHIFT = False #@param {type:\"boolean\"}\n",
        "#@markdown [FORMANT SHIFT SETTINGS] Controls the rate of change of the frequencies in the audio. Increasing this rate can make the frequencies change more rapidly, which can make the sound higher in pitch.\n",
        "QUEFRENCY = 0 #@param {type:\"number\"}\n",
        "#@markdown [FORMANT SHIFT SETTINGS] Controls \"sharpness\" of the audio. Too high of timbre will result in a voice that sounds unnatural, overly processed, or harsh.\n",
        "TIMBRE = 1 #@param {type:\"number\"}\n",
        "#@markdown Finds the closest note in terms of frequency from a predefined set of musical notes, simulating a basic autotune mechanism.\n",
        "F0_AUTOTUNE = False #@param {type:\"boolean\"}\n",
        "#@markdown ### | OUTPUT SETTINGS |\n",
        "#@markdown Specify the desired output format.\n",
        "OUTPUT_FORMAT = \"wav\" #@param [\"wav\", \"flac\", \"mp3\"]\n",
        "\n",
        "if not SOUND_PATH:\n",
        "    os.chdir(os.path.join(main_dir, \"audio_input\"))\n",
        "    uploaded_audio = files.upload()\n",
        "    assert len(uploaded_audio) == 1, \"Please only input audio one at a time\"\n",
        "    SOUND_PATH = os.path.join(os.getcwd(), list(uploaded_audio.keys())[0])\n",
        "    print(f\"To use this audio again without reuploading. Please copy this **{SOUND_PATH}** and paste it in SONG_INPUT\")\n",
        "    os.chdir(main_dir)\n",
        "\n",
        "os.system(\"chmod +x stftpitchshift\")\n",
        "\n",
        "inferred_audio = infer_audio(\n",
        "    MODEL_NAME,\n",
        "    SOUND_PATH,\n",
        "    F0_CHANGE,\n",
        "    F0_METHOD,\n",
        "    MIN_PITCH,\n",
        "    MAX_PITCH,\n",
        "    CREPE_HOP_LENGTH,\n",
        "    INDEX_RATE,\n",
        "    FILTER_RADIUS,\n",
        "    RMS_MIX_RATE,\n",
        "    PROTECT,\n",
        "    SPLIT_INFER,\n",
        "    MIN_SILENCE,\n",
        "    SILENCE_THRESHOLD,\n",
        "    SEEK_STEP,\n",
        "    KEEP_SILENCE,\n",
        "    FORMANT_SHIFT,\n",
        "    QUEFRENCY,\n",
        "    TIMBRE,\n",
        "    F0_AUTOTUNE,\n",
        "    OUTPUT_FORMAT\n",
        ")\n",
        "os.chdir(main_dir)\n",
        "\n",
        "print(f\"Showing {inferred_audio}.\")\n",
        "AudioSegment.from_file(inferred_audio)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uEY1SQk5SYN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
